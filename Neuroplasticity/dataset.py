# ---------- dataset_stream_win.py ----------
# pip install datasets tqdm

import os, itertools
from datasets import load_dataset
from tqdm import tqdm

# 1Ô∏è‚É£  Ruta de cach√© corta
os.environ["HF_HOME"]            = r"C:/hf_cache"
os.environ["HF_HUB_CACHE"]       = r"C:/hf_cache/hub"
os.environ["HF_DATASETS_CACHE"]  = r"C:/hf_cache/datasets"

# 2Ô∏è‚É£  Cargar en streaming (solo 'train')
print("üì• Descargando openwebtext en modo streaming‚Ä¶")
ds_stream = load_dataset(
    "openwebtext",
    split="train",           # ‚Üê no slice aqu√≠
    trust_remote_code=True,
    streaming=True
)

# 3Ô∏è‚É£  Elegir cu√°ntos docs ‚âà 3 GB (ajusta si hace falta)
DOCS_TO_TAKE = 2_000_000      # ~3 GB de texto crudo

# 4Ô∏è‚É£  Guardar con barra de progreso
out_file = "openwebtext_3GB.txt"
with open(out_file, "w", encoding="utf-8") as f:
    for doc in tqdm(itertools.islice(ds_stream, DOCS_TO_TAKE),
                    total=DOCS_TO_TAKE,
                    desc="üì§ Guardando texto"):
        f.write(doc["text"].replace("\n", " ").strip() + "\n")

print(f"\nüéâ Listo ‚Üí {os.path.abspath(out_file)} "
      f"({os.path.getsize(out_file)/(1024**3):.2f} GB)")
# ---------- fin ----------


